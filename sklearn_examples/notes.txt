Supervised Learning (Denetimli Öğrenme): Regresyon(Regression), Sınıflandırma (Classification)
Unsupervised Learning (Denetimsiz Öğrenme): Kümeleme(Clustering) , Boyut İndirgeme (Dimensionality Reduction)
Reinforcement Learning (Pekiştirmeli Öğrenme): Agent

Supervised Learning:

Makine öğrenmesinde bir algoritmanın, girdi verileriyle birlikte doğru çıktıları (etiketleri) gördüğü ve bu örneklerden öğrenerek yeni, görülmemiş veriler için tahmin yapmayı öğrendiği bir yöntemdir.
Veri seti şu şekilde olur:
Girdi (X) → Özellikler (örneğin yaş, kilo, boy)
Çıktı (y) → Etiket (örneğin hastalık var mı, ev fiyatı ne)

Amaç:
Bu girdi-çıktı ilişkisine bakarak, algoritmanın doğru sonuçları tahmin edecek bir model öğrenmesidir.
Supervised learning’in iki temel alt türü vardır:

-Sınıflandırma (Classification): Çıktı kategoriktir (örneğin: evet/hayır, kırmızı/mavi/yeşil)
-Regresyon (Regression): Çıktı sürekli bir değerdir (örneğin: sıcaklık,fiyat)

 -------------------------------------------------------------------------------------------------------------------------

Classification Algoritmaları:

 1) Lojistik Regresyon (Logistic Regression):

 Lojistik regresyon adında regresyon geçmesine rağmen aslında sınıflandırma problemleri için kullanılan bir algoritmadır. Temel amacı, verilen
 girdilere göre bir örneğin belirli bir sınıfa ait olma olasılığını tahmin etmektir. Model önce doğrusal bir regresyon uygular. Sonra bu sonucu
 sigmoid fonksiyonu ile 0-1 aralığına dönüştürerek sınıflandırma yapar. Lojistik regresyon, özellikle ikili sınıflandırma problemlerinde yaygın olarak kullanılır. (Binary Classification)
 Hızlı, basit ve yorumlanabilir bir modeldir. Ancak, doğrusal olmayan ilişkileri modellemek için yeterli olmayabilir.

2) Random Forest Classifier:

Random Forest Classifier (RFC), birden çok karar ağacından oluşan ve her bir ağacın çıktısına göre oy çokluğuyla nihai sınıfı belirleyen bir ensemble (topluluk) öğrenme algoritmasıdır.
Overfitting'e karşı dayanıklıdır çünkü her ağaç farklı bir alt küme üzerinde eğitilir. Bu sayede, modelin genelleme yeteneği artar. Doğruluğu yüksektir. Feature importance (özelliklerin önem derecesi) sağlar.
Dengesiz veri setlerinde bile iyidir. Yorumlanabilirliği daha düşüktür çünkü birden fazla ağaç kullanır. Ayrıca, hiperparametre ayarlamaları gerektirir. Bellek kullanımı fazladır. Çok fazla ağaç varsa, eğitim süresi uzar.
Karmaşık çok boyutlu verilerde iyi sonuç verir. Kredi skorlama, dolandırıcılık tespiti gibi uygulamalarda yaygın olarak kullanılır.

3) Support Vector Classifier (SVC):

SVC, SVM algoritmasının bir uygulamasıdır.Temel amacı, verileri en iyi şekilde ayıran bir hiper düzlem (hyperplane) bulmaktır.
Bu hiper düzlem, iki sınıf arasındaki en büyük marjini (margin) sağlar. SVC, doğrusal ve doğrusal olmayan verilerle çalışabilir. Doğrusal olmayan veriler için kernel trick (çekirdek hilesi) kullanır.
Destek vektörleri (support vectors), sınıfları ayıran en yakın noktaları temsil eder. Bu noktalar, modelin karar sınırını belirler. Kernel trick, verileri daha yüksek boyutlu bir uzaya dönüştürerek doğrusal olmayan sınıflandırma yapmayı sağlar.
Bu sayede, karmaşık veri setlerinde bile iyi sonuçlar elde edilebilir. Az sayıda ama yüksek boyutlu veri setlerinde iyi sonuç verir. Büyük veri setlerinde yavaştır. Parametre ayarı zordur

 Classification Algoritmaları Metrikleri:
    1) Doğruluk (Accuracy): Accuracy, modelin doğru sınıflandırdığı örneklerin toplam örneklere oranıdır.
    2) Kesinlik (Precision): Modelin pozitif olarak tahmin ettiği örneklerin ne kadarının doğru olduğunu gösterir. Yüksek olması durumunda, modelin yanlış pozitif tahminlerde bulunma oranı düşüktür.
    3) Duyarlılık (Recall): Modelin gerçek pozitif örnekleri ne kadar iyi tahmin ettiğini gösterir. Yüksek olması durumunda, modelin yanlış negatif tahminlerde bulunma oranı düşüktür.
    4) F1 Skoru: Kesinlik ve duyarlılığı birleştirerek tek bir metrik sağlar. Özellikle dengesiz veri setlerinde daha anlamlıdır.

 -------------------------------------------------------------------------------------------------------------------------

Regresyon Algoritmaları:

 1) Doğrusal Regresyon (Linear Regression):
    Doğrusal regresyon, bağımlı ve bağımsız değişkenler arasındaki doğrusal ilişkiyi modellemek için kullanılan bir tekniktir. Model, en küçük kareler yöntemi ile
    doğrusal bir fonksiyon oluşturur. Bu fonksiyon, bağımsız değişkenlerin (özelliklerin) ağırlıklı toplamı ile bağımlı değişkenin (sonucun) tahmin edilmesini sağlar.
    Doğrusal regresyon, sürekli bir hedef değişkeni tahmin etmek için kullanılır. Örneğin, bir evin fiyatını tahmin etmek için evin büyüklüğü, konumu gibi özellikleri kullanabiliriz.
    Doğrusal regresyon, basit ve yorumlanabilir bir modeldir. Ancak, doğrusal olmayan ilişkileri modellemek için yeterli olmayabilir. Ayrıca, çoklu doğrusal bağlantı (multicollinearity) gibi sorunlarla karşılaşabiliriz.

 2) Ridge Regresyon (Ridge Regression):
    Ridge regresyon, doğrusal regresyonun bir çeşididir. Temel amacı, modelin karmaşıklığını azaltmak ve aşırı uyum (overfitting) sorununu önlemektir.
    Ridge regresyon, modelin ağırlıklarına L2 ceza terimi ekleyerek çalışır. Bu ceza terimi, ağırlıkların büyüklüğünü sınırlayarak modelin daha basit olmasını sağlar.
    Ridge regresyon, özellikle çoklu doğrusal bağlantı (multicollinearity) sorunları olan veri setlerinde faydalıdır. Ancak, modelin yorumlanabilirliğini azaltabilir.

 3) Lasso Regresyon (Lasso Regression):
    Lasso regresyon, doğrusal regresyona L1 regularizasyon ekler.Bu regularizasyon, bazı katsayıları sıfıra indirerek özellik seçimi (feature selection) de yapar.
    Ridge gibi overfitting'i önlemeye yardımcı olur, ancak bazı özelliklerin tamamen hariç tutulmasına olanak tanır.


 Regresyon Algoritmaları Metrikleri:
    1) Ortalama Mutlak Hata (MAE): Tahmin edilen değerler ile gerçek değerler arasındaki mutlak farkların ortalamasını alır. Ne kadar azsa, model o kadar iyidir. Her hata eşit ağırlık taşır.
    2) Ortalama Kare Hatası (MSE): Tahmin edilen değerler ile gerçek değerler arasındaki farkların karesinin ortalamasını alır. Ne kadar azsa, model o kadar iyidir. Büyük hatalara daha fazla ağırlık verir.
    3) R-kare (R-squared): Modelin veriyi ne kadar iyi açıkladığını gösterir. 1'e yakın değerler, modelin veriyi iyi açıkladığını gösterir.

    MAE yüksek MSE düşükse modelin tahminleri çok iyi değil ama büyük hatalar yapmıyor demektir.
    MSE yüksek MAE düşükse az sayıda büyük hata yapıyor demektir.
 -------------------------------------------------------------------------------------------------------------------------

Unsupervised Learning:
Veriler üzerinde etiket (doğru cevap) olmadan çalışan bir makine öğrenmesi türüdür. Algoritma, verilerdeki gizli desenleri, yapıları veya grupları kendisi keşfetmeye çalışır.
En yaygın örnekleri clustering (kümeleme) ve dimensionality reduction (boyut indirgeme) yöntemleridir. Mesela, müşteri segmentasyonu yapmak ya da benzer belgeleri otomatik gruplamak için kullanılır.


Cluster Algoritmaları:

1) K-Means:
Verileri k adet kümeye (gruba) ayıran popüler bir **clustering (kümeleme) algoritmasıdır. Her kümenin bir merkezi (centroid) vardır ve algoritma verileri bu merkezlere olan uzaklığa göre gruplaştırır.
Başta rastgele seçilen merkezler, veri noktalarına göre tekrar tekrar güncellenir. Amaç, kümeler içindeki noktaların merkezlerine olan toplam uzaklığını (inertia) en aza indirmektir.
Etiketli veri gerekmeden, sadece veri yapısına göre gruplama yapar.

2) DBSCAN:
Yoğunluk temelli bir kümeleme algoritmasıdır. Verileri, yakınında yeterince komşu (min_samples) olan noktaları gruplayarak kümeler oluşturur.
Bu sayede şekli bozuk kümeleri ve aykırı değerleri (noise) başarılı şekilde ayırabilir. Kümeleri önceden belirtmeden otomatik keşfeder, bu yönüyle K-Means’ten farklıdır.
Özellikle gürültülü veya düzensiz yapılı verilerde daha etkilidir.

Clustering Dikkat Edilmesi Gereken Noktalar:

1- Veri ölçeklendirmeden önce clustering yapılmamalı. Standart scalar veya minmax scalar ile veriler ölçeklendirilmeli.
2- Küme sayısı (k) belirlenirken, Elbow yöntemi veya Silhouette skoru gibi yöntemler kullanılabilir. Kmeansde k yı önceden belirlemek zorundayız.
3- Kümeleme algoritmaları, verinin yapısına bağlı olarak farklı sonuçlar verebilir. Bu nedenle, farklı algoritmalarla denemeler yapmak faydalı olabilir.
4- Boyut fazlaysa görsel anlamda küme seçilemez. 2D veya 3D dışındaki kümeleri doğrudan göremeyiz. Bu durumda PCA veya t-SNE gibi boyut indirgeme yöntemleri kullanılabilir.
5- Outlier sonucu bozabilir. Özellikle k-means algoritmasında, outlier'lar küme merkezlerini etkileyebilir. Bu nedenle, öncelikle anomaly detection (anormallik tespiti) yapılabilir.
6- Kümelerin şekli önemlidir. KMeans, küme merkezlerine göre çalıştığı için küme şekilleri küresel olmalıdır. DBSCAN ise yoğunluk temelli olduğu için daha karmaşık şekilleri algılayabilir.
 -------------------------------------------------------------------------------------------------------------------------


-StandardScaler : Özelliklerin ortalamasını 0, standart sapmasını 1 olacak şekilde ölçeklendirir. Bu, özelliklerin aynı ölçek üzerinde olmasını sağlar ve
bazı algoritmaların daha iyi performans göstermesine yardımcı olur. Linear regression, logistic regression, svm, knn, pca, neural network(mlp,tensorflow,keras)
gibi algoritmalar için önemlidir. Decision tree, random forest, xgboost gibi algoritmalar için gerekli değildir.

-Cross Validation: Modelin genelleme yeteneğini değerlendirmek için kullanılır. Veri setini k katmana böler ve her katmanı test seti olarak kullanarak modelin performansını değerlendirir.
Modelin overfitting yapıp yapmadığını anlamak için önemlidir. Genellikle k=5 veya k=10 kullanılır. K-fold cross validation, stratified k-fold cross validation gibi türleri vardır. K-fold cross validation, veri setini k katmana böler ve
her katmanı test seti olarak kullanarak modelin performansını değerlendirir. Veri seti K parçaya bölünür. Her seferinde 1 parça test verisi geri kalan K-1 parça eğitim verisi olarak kullanılır. Bu işlem K kez tekrarlanır ve her seferinde farklı bir parça test verisi olur.
Sonuçta K tane doğruluk skoru elde edilir ve bunların ortalaması alınır. Performans ölçümünde daha güvenilir sonuç verir. Veriyi daha verimli kullanır. Hesaplama maliyeti yüksektir. Eğitim süresi artar.